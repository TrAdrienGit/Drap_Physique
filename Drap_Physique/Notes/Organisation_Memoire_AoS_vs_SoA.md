# Organisation m√©moire : AoS vs SoA

## üì¶ AoS (Array of Structures)

L'approche **AoS** consiste √† regrouper toutes les donn√©es d'un objet (ou sommet) dans une **structure unique**, puis √† stocker un tableau de ces structures.

### Exemple :

```cpp
struct Vertex {
    glm::vec3 position;
    glm::vec3 vitesse;
    glm::vec3 acceleration;
    glm::vec3 normal;
    glm::vec2 uv;
    float masse;
    bool isFixed;
};

std::vector<Vertex> vertices;
```

Chaque √©l√©ment du tableau repr√©sente un **vertex complet**.

### Inconv√©nients :

- Mauvaise **localit√© m√©moire** pour le CPU (cache inefficace).
- Difficile √† **vectoriser automatiquement** (SIMD).
- Moins adapt√© √† des calculs parall√®les.
- Acc√®s dispers√© pour des traitements par champ (ex : toutes les positions).

---

## üß± SoA (Structure of Arrays)

L‚Äôapproche **SoA** consiste √† stocker **chaque champ s√©par√©ment** dans un tableau d√©di√©. Tous les `position` sont dans un tableau, toutes les `vitesse` dans un autre, etc.

### Exemple :

```cpp
std::vector<glm::vec3> positions;
std::vector<glm::vec3> vitesses;
std::vector<glm::vec3> accelerations;
std::vector<glm::vec3> normales;
std::vector<glm::vec2> uvs;
std::vector<float> masses;
std::vector<bool> isFixed;
```

Un **vertex est repr√©sent√© par un index commun** dans tous les tableaux.

### Avantages :

‚úÖ **Meilleure performance CPU** : donn√©es contigu√´s ‚Üí cache efficace  
‚úÖ **Compatibilit√© SIMD** : traitements vectoriels plus rapides  
‚úÖ **Parall√©lisation plus facile** : OpenMP ou autres frameworks  
‚úÖ **Acc√®s plus rapide** sur de grandes structures (grilles, maillages)

---

## ‚öôÔ∏è Pourquoi nous passons √† SoA

Dans le cadre de notre projet de simulation de tissu, nous avons choisi de **remplacer le mod√®le AoS par une approche SoA** pour les raisons suivantes :

- Le syst√®me physique effectue de nombreux acc√®s √† des champs sp√©cifiques (positions, vitesses, normales‚Ä¶)
- La simulation manipule potentiellement **des milliers de sommets**, rendant la performance critique
- Les fonctions de calcul peuvent b√©n√©ficier de la **vectorisation automatique**
- OpenMP et d'autres optimisations CPU n√©cessitent une s√©paration claire des donn√©es

---

## üö´ Suppression de la classe `Vertex`

La cons√©quence directe de cette transition vers SoA est la **suppression de la classe `Vertex`**. Celle-ci n‚Äôest plus n√©cessaire puisque ses champs sont d√©sormais stock√©s ind√©pendamment dans des `std::vector`.

Nous utilisons d√©sormais une classe `TissuSoA`, qui expose une interface optimis√©e, acc√©dant aux champs via un index global calcul√© √† partir des coordonn√©es `(x, y)`.

### Exemple :
```cpp
size_t index = tissu.getIndex(i, j);
tissu.positions[index] += tissu.vitesses[index] * dt;
```

---

## üìå Conclusion

Le passage √† **SoA** permet d'am√©liorer :
- L'efficacit√© m√©moire
- Les performances du CPU
- La scalabilit√© du moteur physique

Cela implique une refactorisation partielle du syst√®me de simulation, mais le **gain en performances et maintenabilit√©** en vaut largement l'effort.
